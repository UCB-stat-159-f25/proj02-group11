{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db21929f-e0b4-4898-a9eb-c91098a2d978",
   "metadata": {},
   "source": [
    "## Part 3: Advanced Text Processing - LDA and BERTopic Topic Modeling (20 pts)\n",
    "\n",
    "**Resources:**\n",
    "- LDA:\n",
    "    - https://medium.com/sayahfares19/text-analysis-topic-modelling-with-spacy-gensim-4cd92ef06e06 \n",
    "    - https://www.kaggle.com/code/faressayah/text-analysis-topic-modeling-with-spacy-gensim#%F0%9F%93%9A-Topic-Modeling (code for previous post)\n",
    "    - https://towardsdatascience.com/topic-modelling-in-python-with-spacy-and-gensim-dc8f7748bdbf/ \n",
    "- BERTopic:\n",
    "    - https://maartengr.github.io/BERTopic/getting_started/visualization/visualize_documents.html#visualize-documents-with-plotly \n",
    "    - https://maartengr.github.io/BERTopic/getting_started/visualization/visualize_topics.html \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71a47df2-e6bf-42a0-8fae-3af9361d9926",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'spacy'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mspacy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m displacy\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mbertopic\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BERTopic\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[34;01mgensim\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcorpora\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dictionary\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'spacy'"
     ]
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "from bertopic import BERTopic\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import LdaModel\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee84460-130b-47df-b0e4-6e907bb807df",
   "metadata": {},
   "source": [
    "### LDA\n",
    "\n",
    "- Train an LDA model with 18 topics\n",
    "- Output the top 10 words for each topic. \n",
    "- Output the topic distribution for the first speech\n",
    "- Make a visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7fb57e-5fa1-456d-a838-4fe6894b69e0",
   "metadata": {},
   "source": [
    "You may use the next two cells to process the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bab11b9-9769-4feb-a92a-abef1170f3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text): \n",
    "    doc = nlp(text) \n",
    "    return [token.lemma_.lower() for token in doc if not token.is_stop and not token.is_punct and not token.is_space and len(token.lemma_) > 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c8a8957-6f1d-4cae-9b60-3f27a9c744c9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sou' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Process all texts - note this takes ~ 5 minutes to run\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m processed_docs = \u001b[43msou\u001b[49m[\u001b[33m'\u001b[39m\u001b[33mText\u001b[39m\u001b[33m'\u001b[39m].apply(preprocess_text)\n",
      "\u001b[31mNameError\u001b[39m: name 'sou' is not defined"
     ]
    }
   ],
   "source": [
    "# Process all texts - note this takes ~ 5 minutes to run\n",
    "processed_docs = sou['Text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040f6b86-e239-43bd-a56a-606d0afce42f",
   "metadata": {},
   "source": [
    "To train an LDA model, use the LdaModel function that we imported a couple of cells back. The last resource linked under the LDA section is especially useful for walking through the steps we have below. *Note: one of the arguments to the LdaModel function is `random_state` which specifies the random seed for reproducibility. Please set yours to 42. Further, the last resource provided uses `LdaMulticore` which is essentially a parallelizable version of our function `LdaModel`. Use `LdaModel` instead, but the usage will be similar, except you can ignore the `iterations` and `workers` arguments..*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e65413f6-ab01-4214-b921-88e2ded269b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build dictionary from processed_docs, which is a list of tokens extracted from our speeches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a20ed12-8f94-4a65-b697-7a7597218af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train LDA model with 18 topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "672dfada-454b-41aa-9dea-77e0916d9b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the top 10 words for each topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a108849f-8f69-4737-ac89-ed9399f2418f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the topic distribution for the first speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63c9825b-3dee-4a90-969a-79331035d51b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pyLDAvis' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# make a visualization using pyLDAvis\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mpyLDAvis\u001b[49m.enable_notebook()\n\u001b[32m      3\u001b[39m ...\n",
      "\u001b[31mNameError\u001b[39m: name 'pyLDAvis' is not defined"
     ]
    }
   ],
   "source": [
    "# make a visualization using pyLDAvis\n",
    "pyLDAvis.enable_notebook()\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d5f4e3-092a-4927-8516-4a136f2e67c1",
   "metadata": {},
   "source": [
    "### BERTopic\n",
    "\n",
    "- Train a BERTopic model with a `min_topic_size` of 3 *Hint: use `BERTopic` to instantiate the model and specify `min_topic_size` in here. Actually fit the model using `fit_transform`, which `docs` passed into this.*\n",
    "- Output the top 10 words for each topic. \n",
    "- Output the topic distribution for the first speech\n",
    "- Make a visualization of the topics (see topic_model.visualize_topics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c18d54c4-3959-4226-b0ef-2dfab390133b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sou' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m docs = \u001b[43msou\u001b[49m[\u001b[33m'\u001b[39m\u001b[33mText\u001b[39m\u001b[33m'\u001b[39m].to_list()\n",
      "\u001b[31mNameError\u001b[39m: name 'sou' is not defined"
     ]
    }
   ],
   "source": [
    "docs = sou['Text'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c59237c-3ce1-40b0-a269-ea81a8f6dca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model - this takes about 30 seconds\n",
    "\n",
    "# remove stop words from the topics (Hint: use CountVectorizer and then .update_topics on topic_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4572431a-49b2-40d8-9a89-610f0ecf02fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output the top 10 words for each topic - hint see get_topic_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d36e7424-f002-47ea-bb3f-069fdda99f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output the topic distribution for the first speech\n",
    "# hint: check out approximate_distribution() and visualize_distribution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "043ffd99-96dc-4a84-b311-bb20e27dbaac",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'topic_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# run this cell to visualize the topics\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mtopic_model\u001b[49m.visualize_topics()\n",
      "\u001b[31mNameError\u001b[39m: name 'topic_model' is not defined"
     ]
    }
   ],
   "source": [
    "# run this cell to visualize the topics\n",
    "topic_model.visualize_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68d2385-f0a8-49e4-8a14-2f1d20fdb56f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
